{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "793207e6-0a0c-4ecf-bf07-bd02236e0c57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301611/3138227286.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  rating_dataset = pd.read_csv(datasetPath,sep='::', nrows = 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    1             122               5     838985046\n",
      "count  1000000.000000  1000000.000000  1000000.000000  1.000000e+06\n",
      "mean      3806.056084     3906.421320        3.522126  1.026182e+09\n",
      "std       2157.229469     8572.503172        1.058205  1.143512e+08\n",
      "min          1.000000        1.000000        0.500000  8.280802e+08\n",
      "25%       1936.000000      640.000000        3.000000  9.460384e+08\n",
      "50%       3810.000000     1721.000000        4.000000  1.023814e+09\n",
      "75%       5707.000000     3471.000000        4.000000  1.118983e+09\n",
      "max       7521.000000    65133.000000        5.000000  1.231130e+09\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(7316, 9626)\n",
      "98.59%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def preprocess(datasetPath = './ratings.dat'):\n",
    "    # PLEASE DELETE THIS LINE LATER: nrows took first 100000 rows for test \n",
    "    rating_dataset = pd.read_csv(datasetPath,sep='::', nrows = 1000000)\n",
    "    print(rating_dataset.describe())\n",
    "    rating_dataset.columns = ['user_id','item_id','rating','timestamp']\n",
    "\n",
    "    mean_rating = rating_dataset['rating'].mean()\n",
    "    min_rating = rating_dataset['rating'].min()\n",
    "    max_rating = rating_dataset['rating'].max()\n",
    "\n",
    "    # if the rating is greater or equal to 4, treat it as positive rating (1); \n",
    "    # otherwise treat it as negative rating (0)\n",
    "    #rating_dataset.loc[:,'rating'] = rating_dataset['rating'].map(lambda x: 1 if x >= 4 else 0)\n",
    "    rating_dataset.loc[:,'rating'] = rating_dataset['rating'].map(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "    \n",
    "    # store the original user_id and item_id lists\n",
    "    user_id_list = sorted(rating_dataset.loc[:,'user_id'].unique().tolist())\n",
    "    item_id_list = sorted(rating_dataset.loc[:,'item_id'].unique().tolist())\n",
    "\n",
    "    item_index = np.arange(len(item_id_list)).tolist()\n",
    "    \n",
    "\n",
    "    # set the initial value (rating) of all the entries as 0 (if the data is NA, leave it as 0)\n",
    "    # user_item_matrix = np.zeros(shape = (len(user_id_list), len(item_id_list)))\n",
    "\n",
    "    # # The (i row, j column) of user_item_matrix means the ith user's rating to the jth movies, \n",
    "    # # Here, i and j are the actual ids' indices in the user_id_list and item_id_list respectively.\n",
    "\n",
    "    # for i in range(len(user_id_list)):\n",
    "    #     for index, row in rating_dataset.groupby(['user_id']).get_group(user_id_list[i]).iterrows():\n",
    "    #         item_id = row['item_id']\n",
    "    #         rating = row ['rating']\n",
    "    #         user_item_matrix[i, item_id_list.index(item_id)] = rating\n",
    "    user_item_matrix = rating_dataset.pivot(index='user_id', columns='item_id', values='rating')\n",
    "    #user_item_matrix = user_item_matrix.subtract(np.float16(user_item_matrix.mean(axis=1)), axis=0)\n",
    "    #similarity_matrix = user_item_matrix.T.corr('pearson', min_periods=1).to_numpy()\n",
    "    user_item_matrix = np.float32(user_item_matrix.fillna(0).to_numpy())\n",
    "    print(user_item_matrix)\n",
    "    print(user_item_matrix.shape)\n",
    "    \n",
    "    # show the sparsity of the user-item matrix\n",
    "    \n",
    "    sparsity = 1.0 - ( np.count_nonzero(user_item_matrix) / (user_item_matrix.shape[0] * user_item_matrix.shape[1]) )\n",
    "    sparsity *= 100\n",
    "    print('{:.2f}%'.format(sparsity))\n",
    "    \n",
    "    return rating_dataset, user_id_list, item_id_list, user_item_matrix\n",
    "\n",
    "rating_dataset, user_id_list, item_id_list, user_item_matrix = preprocess(datasetPath = './ratings.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "387726e0-3bee-4685-adc5-8f36fc0f4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    train = ratings.copy()\n",
    "    \n",
    "    test_time = np.quantile(rating_dataset.timestamp, 0.90)\n",
    "    test_ids = rating_dataset.loc[rating_dataset['timestamp'] > test_time, ['user_id', 'item_id']]\\\n",
    "            .groupby('user_id')\n",
    "    \n",
    "    \n",
    "    test_index_list = []\n",
    "\n",
    "\n",
    "    for uid, mids in test_ids.__iter__():\n",
    "        u_index = user_id_list.index(uid)\n",
    "        mid_list = mids.item_id.to_list()\n",
    "        movie_indices = [item_id_list.index(mid) for mid in mid_list]\n",
    "    \n",
    "        test_index_list.append({u_index:movie_indices})\n",
    "        \n",
    "    \n",
    "    test = np.zeros(ratings.shape)\n",
    "    \n",
    "    for i in test_index_list:\n",
    "        for u_index, m_list in i.items():\n",
    "            train[u_index, m_list] = 0\n",
    "            test[u_index, m_list] = ratings[u_index, m_list]\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "\n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1adc9862-7571-4a1a-9a93-aaad3d13d662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings shape (7316, 9626)  number of nonzero: 991749\n",
      "training shape (7316, 9626)  number of nonzero: 893023\n",
      "test shape (7316, 9626)  number of nonzero: 98726\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(user_item_matrix)\n",
    "print(\"ratings shape\", user_item_matrix.shape, \" number of nonzero:\", np.count_nonzero(user_item_matrix))\n",
    "print(\"training shape\", train.shape, \" number of nonzero:\", np.count_nonzero(train))\n",
    "#print(\"validation shape\", val.shape, \" number of nonzero:\", np.count_nonzero(val))\n",
    "print(\"test shape\", test.shape, \" number of nonzero:\", np.count_nonzero(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ed1d50-775a-4374-9420-23d1b0dbafd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7316, 7316)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Similarity matrix based on pearson correlation\n",
    "#similarity_matirx = user_item_matrix.T.corr()\n",
    "similarity_matrix = np.nan_to_num(np.corrcoef(train), nan=0)\n",
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f300df-153b-4d7e-9e17-bd7e444e8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65d14471-24ec-4073-871d-0fd9eab5b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish the prediction for 0.00% users\n",
      "Finish the prediction for 1.37% users\n",
      "Finish the prediction for 2.73% users\n",
      "Finish the prediction for 4.10% users\n",
      "Finish the prediction for 5.47% users\n",
      "Finish the prediction for 6.83% users\n",
      "Finish the prediction for 8.20% users\n",
      "Finish the prediction for 9.57% users\n",
      "Finish the prediction for 10.93% users\n",
      "Finish the prediction for 12.30% users\n",
      "Finish the prediction for 13.67% users\n",
      "Finish the prediction for 15.04% users\n",
      "Finish the prediction for 16.40% users\n",
      "Finish the prediction for 17.77% users\n",
      "Finish the prediction for 19.14% users\n",
      "Finish the prediction for 20.50% users\n",
      "Finish the prediction for 21.87% users\n",
      "Finish the prediction for 23.24% users\n",
      "Finish the prediction for 24.60% users\n",
      "Finish the prediction for 25.97% users\n",
      "Finish the prediction for 27.34% users\n",
      "Finish the prediction for 28.70% users\n",
      "Finish the prediction for 30.07% users\n",
      "Finish the prediction for 31.44% users\n",
      "Finish the prediction for 32.80% users\n",
      "Finish the prediction for 34.17% users\n",
      "Finish the prediction for 35.54% users\n",
      "Finish the prediction for 36.91% users\n",
      "Finish the prediction for 38.27% users\n",
      "Finish the prediction for 39.64% users\n",
      "Finish the prediction for 41.01% users\n",
      "Finish the prediction for 42.37% users\n",
      "Finish the prediction for 43.74% users\n",
      "Finish the prediction for 45.11% users\n",
      "Finish the prediction for 46.47% users\n",
      "Finish the prediction for 47.84% users\n",
      "Finish the prediction for 49.21% users\n",
      "Finish the prediction for 50.57% users\n",
      "Finish the prediction for 51.94% users\n",
      "Finish the prediction for 53.31% users\n",
      "Finish the prediction for 54.67% users\n",
      "Finish the prediction for 56.04% users\n",
      "Finish the prediction for 57.41% users\n",
      "Finish the prediction for 58.78% users\n",
      "Finish the prediction for 60.14% users\n",
      "Finish the prediction for 61.51% users\n",
      "Finish the prediction for 62.88% users\n",
      "Finish the prediction for 64.24% users\n",
      "Finish the prediction for 65.61% users\n",
      "Finish the prediction for 66.98% users\n",
      "Finish the prediction for 68.34% users\n",
      "Finish the prediction for 69.71% users\n",
      "Finish the prediction for 71.08% users\n",
      "Finish the prediction for 72.44% users\n",
      "Finish the prediction for 73.81% users\n",
      "Finish the prediction for 75.18% users\n",
      "Finish the prediction for 76.54% users\n",
      "Finish the prediction for 77.91% users\n",
      "Finish the prediction for 79.28% users\n",
      "Finish the prediction for 80.65% users\n",
      "Finish the prediction for 82.01% users\n",
      "Finish the prediction for 83.38% users\n",
      "Finish the prediction for 84.75% users\n",
      "Finish the prediction for 86.11% users\n",
      "Finish the prediction for 87.48% users\n",
      "Finish the prediction for 88.85% users\n",
      "Finish the prediction for 90.21% users\n",
      "Finish the prediction for 91.58% users\n",
      "Finish the prediction for 92.95% users\n",
      "Finish the prediction for 94.31% users\n",
      "Finish the prediction for 95.68% users\n",
      "Finish the prediction for 97.05% users\n",
      "Finish the prediction for 98.41% users\n",
      "Finish the prediction for 99.78% users\n"
     ]
    }
   ],
   "source": [
    "top_n = 100\n",
    "prediction_ratings = train.copy()\n",
    "overall_mean = np.mean(train[train.nonzero()])\n",
    "for user_index in range(prediction_ratings.shape[0]):\n",
    "    predictions_indices = np.where(test[user_index, :] > 0)[0]\n",
    "    rated_indices = np.where(train[user_index, :] > 0)[0]\n",
    "\n",
    "\n",
    "        \n",
    "    similarity_row = similarity_matrix[user_index, :]\n",
    "\n",
    "    # sum of similarity in this row\n",
    "    sum_s = sum(similarity_row)\n",
    "    # get top-n similary neighbors except the first one\n",
    "    neighbors = np.argsort(similarity_row)[::-1][:top_n][1:]\n",
    "    #print(neighbors)\n",
    "   \n",
    "    for item_index in predictions_indices:\n",
    "        # find the neighbors who have rated the movie\n",
    "        rated_neighbors = []\n",
    "        for neighbor in neighbors:\n",
    "            if len(rated_neighbors) > 20:\n",
    "                break\n",
    "            if train[neighbor, item_index] > 0:\n",
    "                rated_neighbors.append(neighbor)\n",
    "            \n",
    "        if len(rated_neighbors) > 20:\n",
    "            rated_neighbors = np.array(rated_neighbors)\n",
    "            # print(rated_neighbors)\n",
    "            # print(train[rated_neighbors,item_index])\n",
    "            # print(similarity_row[rated_neighbors])\n",
    "            if sum_s != 0:\n",
    "                prediction_ratings[user_index, item_index] = np.dot(similarity_row[rated_neighbors],\\\n",
    "                 prediction_ratings[rated_neighbors,item_index]) / sum_s\n",
    "            else:\n",
    "                prediction_ratings[user_index, item_index] = overall_mean\n",
    "                \n",
    "            \n",
    "            \n",
    "        elif len(rated_indices) > 0:\n",
    "            # no rated_neighbors, use the mean score\n",
    "            prediction_ratings[user_index, item_index] = train[user_index, rated_indices].mean()\n",
    "        else:\n",
    "            prediction_ratings[user_index, item_index] = overall_mean\n",
    "            \n",
    "\n",
    "    if user_index % 100 == 0:\n",
    "        print('Finish the prediction for {:.2f}% users'.format(user_index/prediction_ratings.shape[0]*100))\n",
    "        #rmse_validation = rmse(prediction_ratings, test)\n",
    "        #print('rmse score is:', rmse_validation)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acd00617-1421-4180-afb9-9d7e3de14c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6368183\n",
      "0.6902268359395813\n",
      "(98726,)\n",
      "(98726,)\n",
      "The auc score is 0.5053460733080465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def map_to_CTR(matrix, nonzero):\n",
    "    CTR = matrix[nonzero].flatten()\n",
    "    thres_hold = 0.8*(CTR.max()-CTR.min())\n",
    "    #print(thres_hold)\n",
    "    for i in range(len(CTR)):\n",
    "        if CTR[i] - CTR.min()  >= thres_hold: \n",
    "        #if CTR[i] >= 0.8:\n",
    "            CTR[i] = 1\n",
    "\n",
    "        else:\n",
    "            CTR[i] = 0\n",
    "\n",
    "    return CTR\n",
    "\n",
    "print(prediction_ratings[test.nonzero()].mean())\n",
    "print(test[test.nonzero()].mean())\n",
    "CTR_predicted_rating = map_to_CTR(prediction_ratings, nonzero = test.nonzero())\n",
    "CTR_validation_rating = map_to_CTR(test, nonzero = test.nonzero())\n",
    "\n",
    "\n",
    "print(CTR_predicted_rating.shape)\n",
    "print(CTR_validation_rating.shape)\n",
    "\n",
    "\n",
    "auc_score =  roc_auc_score(CTR_validation_rating, CTR_predicted_rating)\n",
    "print(\"The auc score is\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0191345-e358-474c-bad4-d994c43a1235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
